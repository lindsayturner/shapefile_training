{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598928610253",
   "display_name": "Python 3.7.7 64-bit ('rf': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This script is testing out the pyspatial library as a tool to create a random forest model on raster data and use that model to predict. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in raster and calculate spectral indices\n",
    "\n",
    "1. Read in and rename raw raster using pyspatialml Raster function\n",
    "2. Calculate spectral indicies\n",
    "3. Use stack function to create new raster of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspatialml import Raster\n",
    "\n",
    "raw_fp = \"data_raw/\" # file path to raw data folder\n",
    "raster_fp = raw_fp + 'white_small_sub.tif' # combine with tif file\n",
    "stack_raw = Raster(raster_fp)\n",
    "stack_raw.names\n",
    "stack_raw.rename({'white_small_sub_1': 'coastal'})\n",
    "stack_raw.rename({'white_small_sub_2': 'blue'})\n",
    "stack_raw.rename({'white_small_sub_3': 'green'})\n",
    "stack_raw.rename({'white_small_sub_4': 'yellow'})\n",
    "stack_raw.rename({'white_small_sub_5': 'red'})\n",
    "stack_raw.rename({'white_small_sub_6': 'rededge'})\n",
    "stack_raw.rename({'white_small_sub_7': 'NIR1'})\n",
    "stack_raw.rename({'white_small_sub_8': 'NIR2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define nre_func\n",
    "def nre_fun(x, y):\n",
    "    nre = (x - y) / (x + y)\n",
    "    return nre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning takes ~10 min to calc all indicies below\n",
    "green_red = nre_fun(stack_raw['green'], stack_raw['red'])\n",
    "blue_coastal = nre_fun(stack_raw['blue'], stack_raw['coastal'])\n",
    "NIR2_yellow = nre_fun(stack_raw['NIR2'], stack_raw['yellow'])\n",
    "NIR1_red = nre_fun(stack_raw['NIR1'], stack_raw['red'])\n",
    "rededge_yellow = nre_fun(stack_raw['rededge'], stack_raw['yellow'])\n",
    "red_NIR2 = nre_fun(stack_raw['red'], stack_raw['NIR2'])\n",
    "rededge_NIR2 = nre_fun(stack_raw['rededge'], stack_raw['NIR2'])\n",
    "rededge_NIR1 = nre_fun(stack_raw['rededge'], stack_raw['NIR1'])\n",
    "green_NIR1 = nre_fun(stack_raw['green'], stack_raw['NIR1'])\n",
    "green_NIR2 = nre_fun(stack_raw['green'], stack_raw['NIR2'])\n",
    "rededge_green = nre_fun(stack_raw['rededge'], stack_raw['green'])\n",
    "rededge_red = nre_fun(stack_raw['rededge'], stack_raw['red'])\n",
    "yellow_NIR1 = nre_fun(stack_raw['yellow'], stack_raw['NIR1'])\n",
    "NIR2_blue = nre_fun(stack_raw['NIR2'], stack_raw['blue'])\n",
    "blue_red = nre_fun(stack_raw['blue'], stack_raw['red'])\n",
    "\n",
    "# Make list of all indicies\n",
    "predictors = [green_red, blue_coastal, NIR2_yellow, NIR1_red,\n",
    "              rededge_yellow, red_NIR2, rededge_NIR2,\n",
    "              rededge_NIR1, green_NIR1, green_NIR2, rededge_green,\n",
    "              rededge_red, yellow_NIR1, NIR2_blue, blue_red]\n",
    "\n",
    "# Stack indicies in new raster\n",
    "stack = Raster(predictors)\n",
    "\n",
    "# Rename each raster in stack\n",
    "feature_names_orig = stack.names\n",
    "\n",
    "feature_names = ['green red', 'blue coastal', 'NIR2 yellow', 'NIR1 red',\n",
    "              'rededge yellow', 'red NIR2', 'rededge NIR2', 'rededge NIR1',\n",
    "              'green NIR1', 'green NIR2', 'rededge green', 'rededge red',\n",
    "              'yellow NIR1', 'NIR2 blue', 'blue red']\n",
    "\n",
    "\n",
    "for n in range(len(feature_names_orig)):\n",
    "    stack.rename({feature_names_orig[n]:feature_names[n]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in shapefile and extract raster values\n",
    "\n",
    "Attempted to use extract_vector with all polygons. Script ran all night and did not finish. Maybe faster to use rasterio mask()?\n",
    "\n",
    "Trying with a small subsample of polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "shapefile_fp = raw_fp + 'Lindsay_white_river_land_cover/Lindsay_white_river_land_cover.shp'\n",
    "training_poly = gpd.read_file(shapefile_fp)\n",
    "\n",
    "\n",
    "training_poly.Classname = pd.Categorical(training_poly.Classname)\n",
    "training_poly.Classcode = training_poly.Classname.cat.codes\n",
    "\n",
    "\n",
    "# Create a small testing shapefile --- !!!full run will need to delete this!!!\n",
    "training_poly = training_poly.groupby('Classcode').head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extraction step below takes a long time using the pyspatialml `extract_vector` tool..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://pyspatialml.readthedocs.io/en/latest/mlworkflow.html#extraction-training-data\n",
    "# had to install rasterio v1.1.5\n",
    "# https://github.com/stevenpawley/Pyspatialml/issues/17\n",
    "df_polygons = stack.extract_vector(training_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Classvalue column to dataframe\n",
    "df_polygons = df_polygons.merge(training_poly.loc[:, (\"Classcode\", \"Classname\")], right_index=True, left_on = 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RF model\n",
    "\n",
    "First step is to sample from each class to get even distribution of classes.\n",
    "\n",
    "NOTE: will need to remove the replace for the full model. Wood does not have enough samples here (n = 288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the extracted data\n",
    "nsamples_class = 5000 # Number of samples to take from each class\n",
    "sample_seed = 42 # seed for random sample\n",
    "features = df_polygons.groupby('Classcode').apply(lambda s: s.sample(nsamples_class, \n",
    "                                                            random_state = sample_seed, \n",
    "                                                            replace=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to clean up any rows with NA values and select the Classvalue as the y predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X data for rf\n",
    "features = features.dropna()\n",
    "\n",
    "# y data for rf\n",
    "labels = features['Classcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Partition data into testing and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features[feature_names],\n",
    "                                                    labels, train_size = 0.9,\n",
    "                                                    random_state = 42,\n",
    "                                                    stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 200,\n",
    "                            max_features = 5,\n",
    "                            random_state = 8)\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "result = permutation_importance(rf, X_train, y_train, random_state = 8)\n",
    "predictions = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "confmat = confusion_matrix(y_test, predictions)\n",
    "df_confmat = pd.DataFrame(confmat)\n",
    "plot_confusion_matrix(rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use RF model to predict raster stack\n",
    "\n",
    "So far have only tested with a dummy model, but seems pretty fast and easy to implement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on full stack\n",
    "result = stack.predict(estimator=rf, dtype = 'int16', nodata=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot classification result\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "result.iloc[0].cmap = \"Dark2\"\n",
    "result.iloc[0].categorical = True\n",
    "result.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing below here"
   ]
  }
 ]
}